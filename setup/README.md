# ğŸ§ ğŸ“š RAG Demo â€“ AI Knowledge Library

In this mini project we turn a PDF into an **AI Knowledge Library** and let an
AI â€œLibrarianâ€ answer questions about it.

You will see:

1. PDF â†’ text â†’ **knowledge cards** (chunks)
2. Each card gets a **secret number code** (embedding)
3. The computer **finds the best cards** for your question (Retrieval)
4. We build an **augmented prompt** and ask the AI (Generation)
5. We save a **long-term memory log** of each question + answer

You only need to run one file: `rag_main.py`.

---

## 1. Folder structure

When you open the project in VS Code, you should see something like:

```text
rag_demo/
  â”œâ”€ rag_main.py                 # ğŸš€ main script you will run
  â”œâ”€ rag_utils/                  # helper modules used by main
  â”‚   â”œâ”€ __init__.py
  â”‚   â”œâ”€ rag_config.py           # paths, model names, constants
  â”‚   â”œâ”€ pdf_utils.py            # PDF â†’ pages â†’ knowledge cards
  â”‚   â”œâ”€ knowledge_library.py    # build & load AI Knowledge Library
  â”‚   â”œâ”€ retrieval.py            # find top-k best knowledge cards
  â”‚   â”œâ”€ prompt_utils.py         # build augmented messages from templates
  â”‚   â”œâ”€ rag_llm.py              # call the LLM and return JSON + usage
  â”‚   â””â”€ memory_store.py         # save long-term memory log
  â””â”€ data/
      â”œâ”€ data_sources/
      â”‚   â””â”€ book.pdf            # the PDF we will use
      â”œâ”€ knowledge_base/
      â”‚   â””â”€ knowledge_library.json   # created on first run
      â”œâ”€ outputs/
      â”‚   â””â”€ conversation_log.jsonl   # long-term memory (one JSON per line)
      â”œâ”€ prompts/
      â”‚   â”œâ”€ system_prompt.txt   # tells the AI its role
      â”‚   â””â”€ user_prompt.txt     # how we show snippets + question
      â””â”€ models/
          â””â”€ ... MiniLM files go here (see next section)
```
