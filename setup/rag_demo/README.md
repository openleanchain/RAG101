# ðŸ§ ðŸ“š RAG Demo â€“ AI Knowledge Library

In this mini project we turn a PDF into an **AI Knowledge Library** and let an
AI â€œLibrarianâ€ answer questions about it.

You will see:

1. PDF â†’ text â†’ **knowledge cards** (chunks)
2. Each card gets a **secret number code** (embedding)
3. The computer **finds the best cards** for your question (Retrieval)
4. We build an **augmented prompt** and ask the AI (Generation)
5. We save a **long-term memory log** of each question + answer

You only need to run one file: `rag_main.py`.

---

## 1. Folder structure

When you open the project in VS Code, you should see something like:

```text
rag_demo/
  â”œâ”€ rag_main.py                 # ðŸš€ main script you will run
  â”œâ”€ rag_utils/                  # helper modules used by main
  â”‚   â”œâ”€ __init__.py
  â”‚   â”œâ”€ rag_config.py           # paths, model names, constants
  â”‚   â”œâ”€ pdf_utils.py            # PDF â†’ pages â†’ knowledge cards
  â”‚   â”œâ”€ knowledge_library.py    # build & load AI Knowledge Library
  â”‚   â”œâ”€ retrieval.py            # find top-k best knowledge cards
  â”‚   â”œâ”€ prompt_utils.py         # build augmented messages from templates
  â”‚   â”œâ”€ rag_llm.py              # call the LLM and return JSON + usage
  â”‚   â””â”€ memory_store.py         # save long-term memory log
  â””â”€ data/
      â”œâ”€ data_sources/
      â”‚   â””â”€ book.pdf            # the PDF we will use
      â”œâ”€ knowledge_base/
      â”‚   â””â”€ knowledge_library.json   # created on first run
      â”œâ”€ outputs/
      â”‚   â””â”€ conversation_log.jsonl   # long-term memory (one JSON per line)
      â”œâ”€ prompts/
      â”‚   â”œâ”€ system_prompt.txt   # tells the AI its role
      â”‚   â””â”€ user_prompt.txt     # how we show snippets + question
      â””â”€ models/
          â””â”€ ... MiniLM files go here (see next section)
```
You will mostly touch:
- data/data_sources/book.pdf
- rag_main.py
 - the two prompt files in data/prompts/ (if you want to change how the AI talks)

## 2. MiniLM model (local copy from a zip)

To keep things fast for class, your teacher will provide a **separate zip file**
that contains the MiniLM embedding model.  
(We do **not** store this big model inside the GitHub repo.)

> **Download link (to be added by teacher):**  
> `<< MINI_LM_MODEL_ZIP_URL_HERE >>`

### Steps for students

1. Download the zip file from the link your teacher gives you.
2. Unzip it into the `data/models/` folder inside this project.

When you finish, it should look like:

```text
rag_demo/
  â””â”€ data/
      â””â”€ models/
          â””â”€ sentence-transformers_all-MiniLM-L6-v2_...   (and other files)
